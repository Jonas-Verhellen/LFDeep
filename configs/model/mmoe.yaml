
_target_: project.model.mixture_of_experts.MMoE

config:
  num_tasks: 641
  num_experts: 10
  num_units: 20

  sequence_len: 100
  num_features: 1278

  use_expert_bias: yes
  use_gate_bias: yes

  expert: configs/model/tcn.yaml
  optimizer: configs/optim/adam.yaml
